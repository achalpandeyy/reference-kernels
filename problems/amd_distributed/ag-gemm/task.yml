# name: ag-gemm

files:
  - {"name": "submission.py", "source": "@SUBMISSION@"}
  - {"name": "task.py", "source": "task.py"}
  - {"name": "utils.py", "source": "../utils.py"}
  - {"name": "reference.py", "source": "reference.py"}
  - {"name": "eval.py", "source": "../eval.py"}

lang: "py"
multi_gpu: true

description: |
  Implement a AllGather-Gemm kernel on a single MI300X device.

  AllGather-Gemm (AG-Gemm) is a technique that combines the AllGather communication
  pattern with General Matrix Multiplication (GEMM) to optimize the performance
  of transformer models on GPUs.

  Your task:
  - Implement the AG-Gemm kernel to perform matrix multiplications
    in a distributed manner, leveraging the AllGather operation to collect
    data from multiple GPUs.
  - Ensure that the implementation is optimized for the MI300X architecture,
    taking advantage of its specific hardware features for maximum performance.

  Input:
  - `data`: Tuple of (input: torch.Tensor, weights: torch.Tensor,
            bias: Optional, None or torch.Tensor)
    - input: Local input tensor of shape [local_M, K].
    - weight: Weight tensor of shape [local_N, K].
    - bias: bias tensor of shape [local_N] or None.

  Output:
  - Tuple containing:
    - output: Resulting tensor of shape [local_M * world_size, local_N]

  The ranking criteria is the geometric mean of the benchmark results.

  For the grand price, your kernel will be evaluated against the speed of light
  analysis and AMD implementations, the solution closest to the speed of light
  and AMD implementations will be awarded the grand price.
  ```
  The speed of light analysis is:
   m      n      k      has_bias      time[us]
   64     18432  7168   False         6.46
   512    12288  4096   True          24.58
   2048   2880   2880   True          23.04
   4096   4096   4096   False         65.54
   8192   14336  4096   True          458.75
   8192   29568  8192   False         946.18
  ```
config:
  main: "eval.py"

templates:
  Python: "submission.py"

ranking_by: "geom"

tests:
  - {"world_size": 8, "m": 64, "n": 2880, "k": 2880, "has_bias": True, "seed":402}
  - {"world_size": 8, "m": 64, "n": 14336, "k": 3584, "has_bias": True, "seed":562}
  - {"world_size": 8, "m": 512, "n": 14336, "k": 3584, "has_bias": True, "seed":531}
  - {"world_size": 8, "m": 512, "n": 36864, "k": 4608, "has_bias": False, "seed":2090}
  - {"world_size": 8, "m": 2048, "n": 7168, "k": 4096, "has_bias": False, "seed":90953}
  - {"world_size": 8, "m": 2048, "n": 30720, "k": 8192, "has_bias": False, "seed":7770}
  - {"world_size": 8, "m": 4096, "n": 2880, "k": 2880, "has_bias": True, "seed":5312}
  - {"world_size": 8, "m": 4096, "n": 2048, "k": 8192, "has_bias": True, "seed":99}
  - {"world_size": 8, "m": 8192, "n": 14336, "k": 3584, "has_bias": True, "seed":11101}
  - {"world_size": 8, "m": 8192, "n": 36864, "k": 4608, "has_bias": True, "seed":42}
  - {"world_size": 8, "m": 8192, "n": 28672, "k": 8192, "has_bias": False, "seed":7188}

benchmarks:
  - {"world_size": 8, "m": 64, "n": 18432, "k": 7168, "has_bias": False, "seed": 1212}
  - {"world_size": 8, "m": 512, "n": 12288, "k": 4096, "has_bias": True, "seed": 8861}
  - {"world_size": 8, "m": 2048, "n": 2880, "k": 2880, "has_bias": True, "seed": 8080}
  - {"world_size": 8, "m": 4096, "n": 4096, "k": 4096, "has_bias": False, "seed": 601}
  - {"world_size": 8, "m": 8192, "n": 14336, "k": 4096, "has_bias": True, "seed": 3062}
  - {"world_size": 8, "m": 8192, "n": 29568, "k": 8192, "has_bias": False, "seed": 4406}

# name: gemm-rs

files:
  - {"name": "submission.py", "source": "@SUBMISSION@"}
  - {"name": "task.py", "source": "task.py"}
  - {"name": "utils.py", "source": "../utils.py"}
  - {"name": "reference.py", "source": "reference.py"}
  - {"name": "eval.py", "source": "../eval.py"}

lang: "py"

description: |
  Implement a Gemm-ReduceScatter kernel on a single MI300X node.

  Gemm-ReduceScatter is a technique that combines the ReduceScatter
  communication pattern with General Matrix Multiplication (GEMM) to optimize
  the performance of transformer models on GPUs. It is particularly useful for
  handling large models that exceed the memory capacity of a single GPU by
  distributing the model across multiple GPUs and efficiently scattering the
  results of matrix multiplications.

  Your task:
  - Implement the Gemm-RS kernel to perform matrix multiplications in a
    distributed manner, leveraging the ReduceScatter operation to distribute
    data across multiple GPUs.
  - Ensure that the implementation is optimized for the MI300X architecture,
    taking advantage of its specific hardware features for maximum performance.

  Input:
  - `data`: Tuple of (input: torch.Tensor, weights: torch.Tensor,
            bias: Optional, None or torch.Tensor)
    - input: Local input tensor of shape [M, local_K].
    - weight: Weight tensor of shape [N, local_K].
    - bias: bias tensor of shape [N] or None.

  Output:
  - Tuple containing:
    - output: Resulting tensor of shape [M // world_size, N]

config:
  main: "eval.py"

templates:
  Python: "submission.py"

ranking_by: "geom"

tests:
  - {"world_size": 8, "m": 8192, "n": 3584, "k": 14336, "has_bias": True, "seed": 42}
  - {"world_size": 8, "m": 8192, "n": 4096, "k": 12288, "has_bias": False, "seed": 6635}
  - {"world_size": 8, "m": 8192, "n": 4608, "k": 36864, "has_bias": True, "seed": 4422}
  - {"world_size": 8, "m": 8192, "n": 8192, "k": 28672, "has_bias": False, "seed": 1536}


benchmarks:
  - {"world_size": 8, "m": 8192, "n": 4096, "k": 14336, "has_bias": True, "seed": 7168}
  - {"world_size": 8, "m": 8192, "n": 8192, "k": 29568, "has_bias": False, "seed": 1024}
  - {"world_size": 8, "m": 8192, "n": 8192, "k": 30720, "has_bias": True, "seed": 2035}
